{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of using Simulations and RealNVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "sys.path.append(\"../core\")\n",
    "sys.path.append(\"../core/simulations\")\n",
    "\n",
    "\n",
    "from losses import getLoss\n",
    "from trainer import Trainer\n",
    "from optimizers import getOpt\n",
    "from network_base import RealNVP\n",
    "from example_data import gen_double_moon_samples\n",
    "from network_logging import *\n",
    "from simulations.visuals import *\n",
    "from simulations.simulations import *\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crescent Moon Example\n",
    "\n",
    "A basic example of the RealNVP network. The data is generated by mixing samples from two similar distributions such that the shape looks like the following:\n",
    "\n",
    "<img src=\"images/doublemoon.png\" width=450 height=175>\n",
    "\n",
    "\n",
    "We want the network to learn how to generate samples from a distribution built from neural network layers. The network starts with being able to generate a simple gaussian distribution and transforms the network parameters so that it generates a more complex distribution.\n",
    "\n",
    "\n",
    "By running the `crescent_moon_example` we generate that network by training over samples generated from the original distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crescent_moon_example():\n",
    "    data = gen_double_moon_samples(10000)\n",
    "    loss = getLoss().ml_loss()\n",
    "    opt = getOpt().rmsprop(1e-4)\n",
    "    model = RealNVP(loss, opt, model_name='double_moon')\n",
    "    model = LogLoss(model)\n",
    "    model = LogTargetPlot(model, xlim=[-5,5], ylim=[-5,5], c='black')\n",
    "    model = Checkpointing(model)\n",
    "    trainer = Trainer(model, data)\n",
    "    trainer.train(20)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = crescent_moon_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = trained.model.forward_sample(10000).numpy().T\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.title(\"Samples from Double Moon Trained Model\")\n",
    "plt.scatter(samples[0], samples[1], s=1.15, c='black', cmap='jet')\n",
    "plt.xlabel(r\"$x_1$\")\n",
    "plt.ylabel(r\"$x_2$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double Well Example\n",
    "\n",
    "Now, we try this same method on data from Molecular Dynamics simulations. We are trying to generate samples based on a double well MD simulation that has two potential wells that look like this:\n",
    "\n",
    "<img src=\"images/doublewell.png\" width=450 height=175>\n",
    "\n",
    "It is often difficult to start a simulation in one well and reach the other because the potential exponentially climbs in between, so we start first by generating samples from the two wells and then the network from that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_well_example():\n",
    "    sim1 = SimulationData(\"configs/double_well_config_1.yml\")\n",
    "    sim2 = SimulationData(\"configs/double_well_config_2.yml\")    \n",
    "    sim1.runSimulation()\n",
    "    sim2.runSimulation()\n",
    "    \n",
    "    a = sim1.getData().squeeze().astype(np.float32)\n",
    "    b = sim2.getData().squeeze().astype(np.float32)\n",
    "    data = np.concatenate((a, b), axis=0)\n",
    "    \n",
    "    \n",
    "    # we need a function to project our samples for the energy function\n",
    "    fx = lambda x: x[0]\n",
    "    \n",
    "    loss = getLoss().ml_kl_loss(simulation=sim1, turnover=100)\n",
    "    opt = getOpt().rmsprop(5e-4)\n",
    "    model = RealNVP(loss, opt, model_name='double_well')\n",
    "    model = LogLoss(model)\n",
    "    model = LogTargetPlot(model, simulation=sim1, xlim=[-3.8,3.8], ylim=[-4.5,4.5])\n",
    "    model = FreeEnergyPlot(model, simulation=sim1, RC_func=fx, reshape=(1, 2))\n",
    "    model = Checkpointing(model)\n",
    "    trainer = Trainer(model, data, batch_size=256)\n",
    "    trainer.train(45)\n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_dw = double_well_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = trained_dw.model.forward_sample(10000).numpy().T\n",
    "sim = SimulationData(\"configs/double_well_config_1.yml\")\n",
    "plt.figure(figsize=(12,8), dpi=150)\n",
    "plt.title(\"Samples from Double Moon Trained Model\")\n",
    "plot_2D_potential(sim.simulation.central_potential, xlim=[-3.8,3.8], ylim=[-4.5,4.5], cmap='jet')\n",
    "plt.scatter(samples[0], samples[1], s=1.15, c='white', cmap='jet')\n",
    "plt.xlim([-3.8,3.8])\n",
    "plt.ylim([-4.5,4.5])\n",
    "plt.xlabel(r\"$x_1$\")\n",
    "plt.ylabel(r\"$x_2$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mueller Potential Well\n",
    "Now we will try and generate samples from another molecular dynamics simualtion, the mueller potential. This potential has three distinct wells given by the following distribution:\n",
    "\n",
    "<img src=\"images/muellerpotential.png\" width=450 height=175>\n",
    "\n",
    "Because of the increased difficulty, we use a different loss function for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mueller_potential_example():\n",
    "    sim1 = SimulationData(\"configs/muller_well_config_1.yml\")\n",
    "    sim2 = SimulationData(\"configs/muller_well_config_2.yml\")\n",
    "    sim3 = SimulationData(\"configs/muller_well_config_3.yml\")\n",
    "    sim1.runSimulation()\n",
    "    sim2.runSimulation()\n",
    "    sim3.runSimulation()\n",
    "    \n",
    "    a = sim1.getData().squeeze().astype(np.float32)\n",
    "    b = sim2.getData().squeeze().astype(np.float32)\n",
    "    c = sim3.getData().squeeze().astype(np.float32)\n",
    "    data = np.concatenate((a, b, c), axis=0)\n",
    "\n",
    "    # a different reaction coordinate projection\n",
    "    fx = lambda x: np.dot(x, np.array([1, -1]))/np.dot(np.array([1,-1]),np.array([1,-1]))\n",
    "    \n",
    "    loss = getLoss().rc_kl_loss(simulation=sim1, rc_func = fx, vmin = 0, vmax=1.5, turnover=100)\n",
    "    opt = getOpt().rmsprop(5e-4)\n",
    "    model = RealNVP(loss, opt, model_name=\"mueller_well\", loc=[-0.25, 0.75], scale=[1.0, 1.0])\n",
    "    model = LogLoss(model)\n",
    "    model = LogTargetPlot(model, simulation=sim1, xlim=[-1.5, 1.1], ylim=[-0.5, 2.])\n",
    "    model = FreeEnergyPlot(model, simulation=sim1, RC_func=fx, reshape=(1, 2))\n",
    "    model = Checkpointing(moodel)\n",
    "    trainer = Trainer(model, data, batch_size=256)\n",
    "    trainer.train(40)\n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_mp = mueller_potential_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = trained_mp.model.forward_sample(10000).numpy().T\n",
    "sim = SimulationData(\"configs/muller_well_config_1.yml\")\n",
    "plt.figure(figsize=(12,8),  dpi=150)\n",
    "plt.title(\"Samples from Mueller Potential Trained Model\")\n",
    "plot_2D_potential(sim.simulation.central_potential, xlim=[-1.5, 1.1], ylim=[-0.5, 2.], cmap='jet')\n",
    "plt.scatter(samples[0], samples[1], s=1.15, c='white', cmap='jet')\n",
    "plt.xlim([-1.5, 1.1])\n",
    "plt.ylim([-0.5, 2.])\n",
    "plt.xlabel(r\"$x_1$\")\n",
    "plt.ylabel(r\"$x_2$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimer Solution Example\n",
    "\n",
    "We are moving from the 2D space and moving into a 72 dimensional space. We have 34 solvent particles and 2 dimer particles each with an x and y coordinate; 36 particles with two dimensions each equaling 72 complete dimensions. Below we have plotted each of the particles in the beginning of the solution. \n",
    "\n",
    "<img src=\"images/dimer.png\" height=175 width=450 />\n",
    "\n",
    "\n",
    "We can see how the dimer reacts within the solvent in the below video:\n",
    "\n",
    "<video controls src=\"images/dimer_vid.mp4\" height=350 width=900 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimer_example():\n",
    "    dimer = SimulationData(\"configs/dimer_sim_config_md_1.yml\")\n",
    "    dimer.loadSimulation(\"data/dimer_md_longer_traj.npy\")\n",
    "    data = dimer.getData().reshape((-1, 72)).astype(np.float32)\n",
    "    fx = lambda x: np.linalg.norm(np.array(x[0:2]) - np.array(x[2:4]))\n",
    "    loss = getLoss().rc_kl_loss(dimer, fx, .5, 2.5, ndims=72)\n",
    "    opt = getOpt().rmsprop(5e-4)\n",
    "    model = RealNVP(loss, opt, in_shape=[data.shape[1]], chain_length=8, nn_layers=[200, 200, 200], loc=[0.]*72, scale=[1.]*72, model_name='dimer')\n",
    "    model = LogLoss(model)\n",
    "    model = FreeEnergyPlot(model, dimer, fx, reshape=(36,2))\n",
    "    model = DimerAverageLocationPlot(model)\n",
    "    model = Checkpointing(model)\n",
    "    trainer = Trainer(model, data)\n",
    "    trainer.train(200)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_dm = dimer_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = trained_dm.forward_sample(10000).numpy().reshape((-1, 36, 2))\n",
    "ap = np.mean(samples, axis=0)\n",
    "fig = plt.figure(figsize=(12,8), dpi=150)\n",
    "plt.xlabel(\"Average X Poisitons\")\n",
    "plt.ylabel(\"Average Y Positions\")\n",
    "plt.title(\"Trained Dimer Model\")\n",
    "plt.plot(ap[0:2, 0], ap[0:2, 1], c='red', linewidth=8/3)\n",
    "plt.plot(ap[0:2, 0], ap[0:2, 1], 'o', c='red', markersize=8, label='Dimer')\n",
    "plt.plot(ap[2:, 0], ap[2:, 1], 'o', c='blue', markersize=8, label='Solvent');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
